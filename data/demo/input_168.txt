168. Comput Methods Programs Biomed. 2020 Feb;184:105117. doi: 
10.1016/j.cmpb.2019.105117. Epub 2019 Oct 4.

Deep contextualized embeddings for quantifying the informative content in 
biomedical text summarization.

Moradi M(1), Dorffner G(2), Samwald M(2).

Author information:
(1)Institute for Artificial Intelligence and Decision Support, Center for 
Medical Statistics, Informatics, and Intelligent Systems, Medical University of 
Vienna, Vienna, Austria. Electronic address: 
milad.moradivastegani@meduniwien.ac.at.
(2)Institute for Artificial Intelligence and Decision Support, Center for 
Medical Statistics, Informatics, and Intelligent Systems, Medical University of 
Vienna, Vienna, Austria.

BACKGROUND AND OBJECTIVE: Capturing the context of text is a challenging task in 
biomedical text summarization. The objective of this research is to show how 
contextualized embeddings produced by a deep bidirectional language model can be 
utilized to quantify the informative content of sentences in biomedical text 
summarization.
METHODS: We propose a novel summarization method that utilizes contextualized 
embeddings generated by the Bidirectional Encoder Representations from 
Transformers (BERT) model, a deep learning model that recently demonstrated 
state-of-the-art results in several natural language processing tasks. We 
combine different versions of BERT with a clustering method to identify the most 
relevant and informative sentences of input documents. Using the ROUGE toolkit, 
we evaluate the summarizer against several methods previously described in 
literature.
RESULTS: The summarizer obtains state-of-the-art results and significantly 
improves the performance of biomedical text summarization in comparison to a set 
of domain-specific and domain-independent methods. The largest language model 
not specifically pretrained on biomedical text outperformed other models. 
However, among language models of the same size, the one further pretrained on 
biomedical text obtained best results.
CONCLUSIONS: We demonstrate that a hybrid system combining a deep bidirectional 
language model and a clustering method yields state-of-the-art results without 
requiring labor-intensive creation of annotated features or knowledge bases or 
computationally demanding domain-specific pretraining. This study provides a 
starting point towards investigating deep contextualized language models for 
biomedical text summarization.

Copyright Â© 2019. Published by Elsevier B.V.

DOI: 10.1016/j.cmpb.2019.105117
PMID: 31627150

Conflict of interest statement: Declaration of Competing Interest The authors 
have no conflicts of interest to declare.