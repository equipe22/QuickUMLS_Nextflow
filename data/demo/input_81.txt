81. Brief Bioinform. 2014 Mar;15(2):327-40. doi: 10.1093/bib/bbs084. Epub 2012 Dec 
18.

A survey on annotation tools for the biomedical literature.

Neves M(1), Leser U.

Author information:
(1)Department of Computer Science, Humboldt-Universit√§t zu Berlin, Rudower 
Chaussee 25, 12489 Berlin, Germany. neves@informatik.hu-berlin.de.

New approaches to biomedical text mining crucially depend on the existence of 
comprehensive annotated corpora. Such corpora, commonly called gold standards, 
are important for learning patterns or models during the training phase, for 
evaluating and comparing the performance of algorithms and also for better 
understanding the information sought for by means of examples. Gold standards 
depend on human understanding and manual annotation of natural language text. 
This process is very time-consuming and expensive because it requires high 
intellectual effort from domain experts. Accordingly, the lack of gold standards 
is considered as one of the main bottlenecks for developing novel text mining 
methods. This situation led the development of tools that support humans in 
annotating texts. Such tools should be intuitive to use, should support a range 
of different input formats, should include visualization of annotated texts and 
should generate an easy-to-parse output format. Today, a range of tools which 
implement some of these functionalities are available. In this survey, we 
present a comprehensive survey of tools for supporting annotation of biomedical 
texts. Altogether, we considered almost 30 tools, 13 of which were selected for 
an in-depth comparison. The comparison was performed using predefined criteria 
and was accompanied by hands-on experiences whenever possible. Our survey shows 
that current tools can support many of the tasks in biomedical text annotation 
in a satisfying manner, but also that no tool can be considered as a true 
comprehensive solution.

DOI: 10.1093/bib/bbs084
PMID: 23255168 [Indexed for MEDLINE]